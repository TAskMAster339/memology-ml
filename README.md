# üß† Memology-ML ‚Äî AI Meme Generation Engine

[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[üá∑üá∫ –†—É—Å—Å–∫–∞—è –≤–µ—Ä—Å–∏—è](README_RU.md)

**Memology-ML** is the core machine learning component of the **Memology** project ‚Äî an AI-powered meme generation platform. This module creates **visual meme content** and **funny captions** using Stable Diffusion WebUI and Ollama (LLaMA 3.2). All processing runs **locally**, so your memes are created **privately and offline**.

## üé® Example Memes

| Input Idea                | Generated Meme                                               |
| ------------------------- | ------------------------------------------------------------ |
| "–∫–æ—Ç –ø—å–µ—Ç –∫–æ—Ñ–µ"           | ![Cat drinking coffee](examples/cat_with_coffee_example.png) |
| "–ª–æ—à–∞–¥—å —á–∏—Ö–Ω—É–ª–∞"          | ![Horse sneezed](examples/horse_example.png)                 |
| "–∫–æ–º–ø—å—é—Ç–µ—Ä –∏ –µ–∂—É –ø–æ–Ω—è—Ç–µ–Ω" | ![Computer obvious](examples/computer_example.png)           |

## ‚ú® Features

- üñºÔ∏è **High-quality local generation** ‚Äî All processing happens on your machine
- üé® **Multiple visual styles** ‚Äî Realistic, anime, cartoon, cyberpunk, fantasy, and more
- üß† **Smart prompt engineering** ‚Äî Automatic English prompts from Russian ideas
- üòÇ **Witty captions** ‚Äî Short, funny Russian captions generated by AI
- ‚úçÔ∏è **Automatic text overlay** ‚Äî Professional meme-style text with Impact font
- üìä **Comprehensive logging** ‚Äî Full generation process tracking
- üèóÔ∏è **Clean OOP architecture** ‚Äî Modular, testable, and extensible codebase
- ‚öôÔ∏è **Flexible configuration** ‚Äî Environment variables and config files support

## üèóÔ∏è Architecture

The project follows modern **Object-Oriented Programming** principles with clear separation of concerns:

```
memology-ml/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ config/          # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ core/            # LLM and image generation abstractions
‚îÇ   ‚îú‚îÄ‚îÄ services/        # Business logic (prompts, captions, orchestration)
‚îÇ   ‚îú‚îÄ‚îÄ utils/           # Helper utilities (logging, image processing)
‚îÇ   ‚îî‚îÄ‚îÄ models/          # Data models and structures
‚îú‚îÄ‚îÄ tests/               # Unit tests
‚îú‚îÄ‚îÄ examples/            # Example memes
‚îú‚îÄ‚îÄ generated_images/    # Output directory
‚îú‚îÄ‚îÄ main.py             # Application entry point
‚îî‚îÄ‚îÄ requirements.txt    # Python dependencies
```

### Key Components

- **ConfigManager** ‚Äî Centralized configuration with `.env` support
- **LLMClient** ‚Äî Abstraction for Ollama interactions
- **ImageGenerator** ‚Äî Stable Diffusion WebUI integration
- **PromptService** ‚Äî Visual prompt generation
- **CaptionService** ‚Äî Meme caption creation
- **MemeService** ‚Äî Main orchestration service
- **ImageUtils** ‚Äî Image manipulation and text overlay

## üìã Requirements

- **Python** 3.13+
- **Ollama** with LLaMA 3.2 model
- **Stable Diffusion WebUI** (AUTOMATIC1111)
- **Impact font** (`impact.ttf`)

## ‚öôÔ∏è Installation

### 1Ô∏è‚É£ Clone the repository

```bash
git clone https://github.com/TAskMAster339/memology-ml.git
cd memology-ml
```

### 2Ô∏è‚É£ Create and activate virtual environment

```bash
# Linux / macOS
python -m venv venv
source venv/bin/activate

# Windows
python -m venv venv
venv\Scripts\activate
```

### 3Ô∏è‚É£ Install dependencies

```bash
pip install -r requirements.txt
```

## üß† Ollama Setup

### Install Ollama

üëâ [https://ollama.com/download](https://ollama.com/download)

### Pull the LLaMA 3.2 model

```bash
ollama pull llama3.2:3b
```

Verify installation:

```bash
ollama run llama3.2:3b
```

## üé® Stable Diffusion WebUI Setup

### 1Ô∏è‚É£ Install WebUI

üëâ [https://github.com/AUTOMATIC1111/stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui)

### 2Ô∏è‚É£ Run WebUI with API enabled

```bash
python launch.py --api
```

This starts the API at: `http://127.0.0.1:7860/sdapi/v1/txt2img`

### 3Ô∏è‚É£ (Optional) Add custom models

Download additional models from [Civitai](https://civitai.com/):

| Model            | Style                      | Link                                                        |
| ---------------- | -------------------------- | ----------------------------------------------------------- |
| **Memes XL**     | Meme-style, funny, vibrant | [Download](https://civitai.com/models/205229/memes-xl)      |
| **Crazy Horror** | Dark, surreal, horror      | [Download](https://civitai.com/models/1101129/crazy-horror) |

Place downloaded `.safetensors` files into:

```
stable-diffusion-webui/models/Stable-diffusion/
```

## üîß Configuration

Create a `.env` file in the project root (see `.env.example`):

```env
# Ollama Configuration
OLLAMA_MODEL=llama3.2:3b
OLLAMA_TIMEOUT=15
OLLAMA_BASE_URL=http://localhost:11434

# Stable Diffusion Configuration
SD_BASE_URL=http://127.0.0.1:7860
SD_STEPS=20
SD_WIDTH=512
SD_HEIGHT=512
SD_SAMPLER=DPM++ 2M Karras
SD_CFG_SCALE=7.0
SD_RESTORE_FACES=True

# Application Settings
OUTPUT_DIR=generated_images
LOG_FILE=generation.log
FONT_PATH=impact.ttf
```

### Configuration Options

| Parameter                | Description                   | Default           |
| ------------------------ | ----------------------------- | ----------------- |
| `OLLAMA_MODEL`           | LLM model name                | `llama3.2:3b`     |
| `OLLAMA_TIMEOUT`         | LLM request timeout (seconds) | `15`              |
| `SD_STEPS`               | Diffusion steps               | `20`              |
| `SD_WIDTH` / `SD_HEIGHT` | Image dimensions              | `512x512`         |
| `SD_SAMPLER`             | Sampling method               | `DPM++ 2M Karras` |
| `SD_CFG_SCALE`           | Prompt adherence strength     | `7.0`             |

## üöÄ Usage

### Basic Usage

```bash
python main.py
```

The application will generate memes for predefined examples and save them to `generated_images/`.

### Programmatic Usage

```python
from src.services.meme_service import MemeService
from main import create_meme_service

# Initialize the service
meme_service = create_meme_service()

# Generate a meme
result = meme_service.generate_meme("–∫–æ—Ç –ø—å–µ—Ç –∫–æ—Ñ–µ")

if result.success:
    print(f"Meme created: {result.final_image_path}")
    print(f"Caption: {result.caption}")
else:
    print(f"Error: {result.error_message}")
```

### Custom Styles

```python
from src.models.meme import MemeStyle

# Define custom style
custom_style = MemeStyle(
    name="retro",
    description="retro 80s style, neon colors, vaporwave aesthetic"
)

# Generate with custom style
result = meme_service.generate_meme("–∫–æ—Ç –≤ –∫–æ—Å–º–æ—Å–µ", style=custom_style)
```

## üìä Logging

Each generation is logged to `generation.log`:

```
2025-10-26 23:56:10 | src.services.meme_service | INFO | Starting meme generation: 9e0bbf0f
2025-10-26 23:56:22 | src.services.prompt_service | INFO | Generated prompt: A cat drinking coffee...
2025-10-26 23:56:24 | src.services.caption_service | INFO | Generated caption: –ö–æ—Ç –ø—Ä–æ—Å—Ç–æ –Ω–µ —É–º–µ–µ—Ç
2025-10-26 23:58:24 | src.services.meme_service | INFO | Meme generation completed in 134.12s
```

## üß™ Testing

Run unit tests:

```bash
python -m pytest tests/
```

## üõ†Ô∏è Development

### Project Structure Philosophy

The project follows **SOLID principles** and clean architecture:

- **Single Responsibility** ‚Äî Each class has one clear purpose
- **Open/Closed** ‚Äî Open for extension, closed for modification
- **Dependency Injection** ‚Äî Dependencies passed via constructors
- **Separation of Concerns** ‚Äî Business logic separated from infrastructure

### Adding New Features

**Example: Add a new LLM provider**

1. Create a new class in `src/core/llm_client.py`:

```python
class OpenAIClient(BaseLLMClient):
    def generate(self, messages, timeout=None):
        # Implementation
        pass
```

2. Update `main.py` to use the new client:

```python
llm_client = OpenAIClient(api_key=config.openai_api_key)
```

**Example: Add a new image style**

1. Add to `src/models/meme.py`:

```python
PREDEFINED_STYLES.append(
    MemeStyle("steampunk", "steampunk art, Victorian era, brass and copper")
)
```

## üìù API Documentation

### MemeService

**`generate_meme(user_input: str, style: Optional[MemeStyle] = None) -> MemeGenerationResult`**

Generates a meme from user input.

- **Parameters:**
  - `user_input` ‚Äî Meme idea in Russian
  - `style` ‚Äî Visual style (random if None)
- **Returns:** `MemeGenerationResult` with paths and metadata

### PromptService

**`generate_visual_prompt(user_text: str, style: MemeStyle, max_retries: int = 1) -> str`**

Creates an English visual prompt for image generation.

### CaptionService

**`generate_caption(scene_description: str) -> str`**

Generates a short, funny Russian caption.

## ü§ù Contributing

Contributions are welcome! Here's how:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes following the project structure
4. Add tests for new functionality
5. Run tests: `pytest tests/`
6. Commit changes (`git commit -m 'Add amazing feature'`)
7. Push to branch (`git push origin feature/amazing-feature`)
8. Open a Pull Request

### Code Style

- Follow PEP 8 guidelines
- Use type hints
- Add docstrings to public methods
- Keep classes focused and small

## üí° Tips & Optimization

- **Faster generation:** Reduce `SD_STEPS` to `10-15`
- **Better quality:** Use SDXL models or increase steps to `30-40`
- **Dark memes:** Try the "Crazy Horror" model
- **Anime style:** Use "Anything V5" model
- **Everything works offline** ‚Äî No API keys required!

## üêõ Troubleshooting

### Common Issues

**Issue:** `ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=7860)`

**Solution:**

- Ensure Stable Diffusion WebUI is running with `--api` flag
- Check that WebUI is accessible at http://127.0.0.1:7860

**Issue:** `ConnectionRefusedError` for Ollama

**Solution:**

- Start Ollama: `ollama serve`
- Verify model is installed: `ollama list`

**Issue:** Text doesn't fit on image

**Solution:**

- Font file missing ‚Äî ensure `impact.ttf` exists
- Reduce caption length in prompt

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- [Ollama](https://ollama.com/) ‚Äî Local LLM runtime
- [AUTOMATIC1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui) ‚Äî Stable Diffusion WebUI
- [Stability AI](https://stability.ai/) ‚Äî Stable Diffusion model

## üì¨ Contact

Project Link: [https://github.com/TAskMAster339/memology-ml](https://github.com/TAskMAster339/memology-ml)

---

**Built with ‚ù§Ô∏è and AI** | Made for meme enthusiasts and ML practitioners
