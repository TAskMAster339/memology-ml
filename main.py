import base64
import logging
import os
import random
import textwrap
import threading
import time
from datetime import datetime
from io import BytesIO
from uuid import uuid4

import ollama
import requests
from PIL import Image, ImageDraw, ImageFont

# === –ù–ê–°–¢–†–û–ô–ö–ò ===
MODEL = "llama3.2:3b"
OUTPUT_DIR = "generated_images"
LOG_FILE = "generation.log"

os.makedirs(OUTPUT_DIR, exist_ok=True)

# === –õ–û–ì–ò–†–û–í–ê–ù–ò–ï ===
logger = logging.getLogger("meme_generator")
logger.setLevel(logging.INFO)
handler = logging.FileHandler(LOG_FILE, encoding="utf-8")
formatter = logging.Formatter(
    "%(asctime)s | %(levelname)s | %(message)s",
    "%Y-%m-%d %H:%M:%S",
)
handler.setFormatter(formatter)
logger.addHandler(handler)

# === –ü–†–û–ú–ü–¢–´ ===
PROMPT_GENERATOR_SYSTEM = """
You are a professional prompt engineer for Stable Diffusion and your task is to create a single high-quality English text description of an image.

Requirements:
- Output only the prompt text ‚Äî one paragraph, no formatting, no quotes, no explanations.
- The style must be visually rich and cinematic.
- Include details about lighting, mood, color palette, and depth of field.
- Use realistic or artistic rendering styles such as:
  "ultra realistic", "studio lighting", "anime style", "cinematic lighting", "digital art", "hyperdetailed", "4k render".
- Adapt the style to match the topic:
   - use "anime style" or "cartoon" for fun, lighthearted, or cute topics;
   - use "realistic", "cinematic lighting" for serious, dramatic, or lifelike ideas.
- Mention a suitable camera angle (e.g., ‚Äúclose-up‚Äù, ‚Äúwide shot‚Äù, ‚Äúfrom above‚Äù, ‚Äúportrait‚Äù, etc.) when relevant.
- Never use markdown, colons, explanations, or any meta instructions.
- The text should be directly usable as a Stable Diffusion prompt.

Example topics and how to respond:
User: "cat drinking coffee"
Output: "a fluffy cat with round cheeks sitting at a cozy table, holding a steaming coffee cup, warm morning sunlight, cinematic lighting, ultra realistic, 4k render, depth of field"
"""


CAPTION_GENERATOR_SYSTEM = """
–¢—ã ‚Äî –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–æ—Ä–æ—Ç–∫–∏—Ö –º–µ–º–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–µ–π.
–°–æ–∑–¥–∞–≤–∞–π –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–º–µ—à–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ (2‚Äì4 —Å–ª–æ–≤).
–ò—Å–ø–æ–ª—å–∑—É–π —Å–∞—Ä–∫–∞–∑–º, —Å–∞–º–æ–∏—Ä–æ–Ω–∏—é, –∏—Ä–æ–Ω–∏—é –∏–ª–∏ –∂–∏–∑–Ω–µ–Ω–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏.
–ù–µ —É–ø–æ–º–∏–Ω–∞–π –ª—é–¥–µ–π, –±—Ä–µ–Ω–¥—ã, –ø–æ–ª–∏—Ç–∏–∫—É –∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π –≥—Ä—É–±–æ—Å—Ç–∏.
–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –ø–æ–¥–ø–∏—Å—å—é, –±–µ–∑ –∫–∞–≤—ã—á–µ–∫ –∏ –ø–æ—è—Å–Ω–µ–Ω–∏–π.
"""

STYLES = [
    "anime style, vibrant colors, soft lighting, detailed, 4k render",
    "ultra realistic, cinematic lighting, shallow depth of field, photo style, HDR, 8k",
    "cartoon style, exaggerated expressions, colorful, flat shading, digital illustration",
    "cyberpunk, neon lights, futuristic atmosphere, dark streets, glowing reflections",
    "fantasy art, mystical lighting, ethereal glow, highly detailed, magical realism",
    "oil painting, baroque composition, dramatic shadows, rich colors, textured brushstrokes",
    "watercolor art, pastel tones, dreamy mood, soft contrast",
    "pixel art, retro video game vibe, limited palette, crisp edges",
]


# === –£–¢–ò–õ–ò–¢–´ ===
def run_with_timeout(func, timeout, *args, **kwargs):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏."""
    result = [None]
    thread = threading.Thread(
        target=lambda: result.__setitem__(0, func(*args, **kwargs)),
    )
    thread.daemon = True
    thread.start()
    thread.join(timeout)
    if thread.is_alive():
        raise TimeoutError(
            f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ {func.__name__} –ø—Ä–µ–≤—ã—à–µ–Ω–æ ({timeout} —Å–µ–∫)",
        )
    return result[0]


def get_random_style():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Å—Ç–∏–ª—å –∏–∑ —Å–ø–∏—Å–∫–∞."""
    return random.choice(STYLES)  # noqa: S311


def clean_prompt(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç –ª–∏—à–Ω–∏–µ –∫—É—Å–∫–∏ –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≤—Å—Ç–∞–≤–∫–∏."""
    stop_phrases = ["Instruction", "Explanation", "Note", "Ensure", "Remember"]
    for phrase in stop_phrases:
        idx = text.find(phrase)
        if idx != -1:
            text = text[:idx].strip()
    return text.replace("**", "").replace("```", "").strip()


# === LLM ===
def generate_visual_prompt(user_text: str, retries=1):
    """–°–æ–∑–¥–∞—ë—Ç –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    try:
        style = get_random_style()
        response = run_with_timeout(
            ollama.chat,
            15,
            model=MODEL,
            messages=[
                {"role": "system", "content": PROMPT_GENERATOR_SYSTEM},
                {
                    "role": "user",
                    "content": f"Describe this scene in English: {user_text}. Style: {style}.",
                },
            ],
        )
        raw = clean_prompt(response["message"]["content"])
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–∏—Ä–∏–ª–ª–∏—Ü–∞
        if any("–∞" <= c.lower() <= "—è" for c in raw):
            if retries > 0:
                logger.warning(
                    "‚ö†Ô∏è –ü—Ä–æ–º–ø—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å —É—Ç–æ—á–Ω–µ–Ω–∏–µ–º —è–∑—ã–∫–∞.",
                )
                return generate_visual_prompt(
                    f"{user_text}. Answer ONLY in English.",
                    retries - 1,
                )
            logger.warning(
                "‚ùå –ú–æ–¥–µ–ª—å —Å–Ω–æ–≤–∞ –æ—Ç–≤–µ—Ç–∏–ª–∞ –Ω–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å.",
            )
        else:
            return raw
    except TimeoutError as e:
        logger.error(f"‚è±Ô∏è –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–∞: {e}")
        return "A funny cat sitting at a table, holding a cup of coffee, cinematic lighting."


def generate_caption(scene_description: str):
    """–°–æ–∑–¥–∞—ë—Ç –∫–æ—Ä–æ—Ç–∫—É—é –ø–æ–¥–ø–∏—Å—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º."""
    try:
        response = run_with_timeout(
            ollama.chat,
            10,
            model=MODEL,
            messages=[
                {"role": "system", "content": CAPTION_GENERATOR_SYSTEM},
                {"role": "user", "content": scene_description},
            ],
        )
        text = clean_prompt(response["message"]["content"])
        return text.split("\n")[0][:80]
    except TimeoutError as e:
        logger.error(f"‚è±Ô∏è –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–¥–ø–∏—Å–∏: {e}")
        return "–ö–æ–≥–¥–∞ –∫–æ—Ñ–µ –Ω–µ –ø–æ–º–æ–≥–∞–µ—Ç"


# === –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ï ===
def generate_image(prompt):
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –ø–æ–¥ —Å–∫–æ—Ä–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ
    payload = {
        "prompt": prompt,
        "steps": 20,  # –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –¥–µ—Ç–∞–ª–µ–π, –Ω–æ –Ω–µ —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ
        "width": 512,  # –±—ã—Å—Ç—Ä–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
        "height": 512,
        "sampler_index": "DPM++ 2M Karras",  # —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏/–∫–∞—á–µ—Å—Ç–≤—É
        "cfg_scale": 7,  # –Ω–∞—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–≥–æ —Å–ª–µ–¥–æ–≤–∞—Ç—å –ø—Ä–æ–º–ø—Ç—É
        "restore_faces": True,  # –µ—Å–ª–∏ –µ—Å—Ç—å –ª–∏—Ü–∞ ‚Äî —É–ª—É—á—à–∞–µ—Ç
        "batch_size": 1,
        "n_iter": 1,
        "seed": -1,  # —Å–ª—É—á–∞–π–Ω—ã–π —Å–∏–¥ –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
        "negative_prompt": (
            "low quality, blurry, bad anatomy, distorted, extra limbs, "
            "poorly drawn, text, watermark, signature, logo"
        ),
        # "model": "v1-5-pruned-emaonly",  # üëà —É–∫–∞–∑—ã–≤–∞–µ–º –Ω—É–∂–Ω—É—é –º–æ–¥–µ–ª—å
    }
    r = requests.post("http://127.0.0.1:7860/sdapi/v1/txt2img", json=payload)
    image_base64 = r.json()["images"][0]
    image = Image.open(BytesIO(base64.b64decode(image_base64)))

    filename = (
        f"meme_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid4().hex[:6]}_raw.png"
    )
    path = os.path.join(OUTPUT_DIR, filename)
    image.save(path)
    return path


# === CAPTION DRAWING ===
def add_caption(image_path, text):
    image = Image.open(image_path).convert("RGB")
    draw = ImageDraw.Draw(image)

    font_path = "impact.ttf"
    # –Ω–∞—á–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞ ‚Äî –ø—Ä–∏–º–µ—Ä–Ω–æ 10% –æ—Ç –≤—ã—Å–æ—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    font_size = int(image.height * 0.1)
    max_width = int(image.width * 0.95)
    max_height = int(image.height * 0.35)

    # —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤ —Ç–µ–∫—Å—Ç–∞
    def get_text_size(lines, font):
        total_height = 0
        max_line_width = 0
        for line in lines:
            bbox = draw.textbbox((0, 0), line, font=font)
            w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]
            total_height += h + 5
            max_line_width = max(max_line_width, w)
        return max_line_width, total_height

    # —É–º–µ–Ω—å—à–∞–µ–º —à—Ä–∏—Ñ—Ç, –ø–æ–∫–∞ –≤—Å—ë –Ω–µ –≤–ª–µ–∑–µ—Ç
    while font_size > 16:
        font = ImageFont.truetype(font_path, font_size)
        # —à–∏—Ä–∏–Ω—É wrap –ø–æ–¥–±–∏—Ä–∞–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏
        wrap_width = max(8, int(image.width / (font_size * 0.6)))
        lines = textwrap.wrap(text, width=wrap_width)
        text_w, text_h = get_text_size(lines, font)
        if text_w <= max_width and text_h <= max_height:
            break
        font_size -= 2

    # –≤—ã—á–∏—Å–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é –ø–æ–∑–∏—Ü–∏—é (—á—É—Ç—å –≤—ã—à–µ –Ω–∏–∂–Ω–µ–≥–æ –∫—Ä–∞—è)
    y = image.height - text_h - int(image.height * 0.03)

    for line in lines:
        bbox = draw.textbbox((0, 0), line, font=font)
        w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]
        x = (image.width - w) / 2

        # –æ–±–≤–æ–¥–∫–∞ (—á–µ—Ä–Ω—ã–π –∫–æ–Ω—Ç—É—Ä)
        for dx in range(-3, 4):
            for dy in range(-3, 4):
                if dx != 0 or dy != 0:
                    draw.text((x + dx, y + dy), line, font=font, fill="black")

        # –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç (–±–µ–ª—ã–π)
        draw.text((x, y), line, font=font, fill="white")
        y += h + 5

    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ç–æ–≥–æ–≤—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É
    filename = (
        f"meme_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid4().hex[:6]}_final.png"
    )
    output_path = os.path.join(OUTPUT_DIR, filename)
    image.save(output_path)
    return output_path


# === PIPELINE ===
def main():
    # user_input = input("\nüí° –í–≤–µ–¥–∏—Ç–µ –∏–¥–µ—é –¥–ª—è –º–µ–º–∞: ").strip()
    user_input = """
    –ö–æ–º–ø—å—é—Ç–µ—Ä –∏ –µ–∂—É –ø–æ–Ω—è—Ç–µ–Ω"""
    if not user_input:
        print("‚ö†Ô∏è –ò–¥–µ—è –Ω–µ –≤–≤–µ–¥–µ–Ω–∞, –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
        return

    start_time = time.time()
    print("\nüß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–∞...")
    visual_prompt = generate_visual_prompt(
        f"{user_input}. Style: anime style, vibrant colors, detailed, 4k render",
    )
    print("üé® –ü—Ä–æ–º–ø—Ç:", visual_prompt)

    print("\nüñºÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Stable Diffusion...")
    image_path = generate_image(visual_prompt)

    print("\nüòÇ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–¥–ø–∏—Å–∏ –¥–ª—è –º–µ–º–∞...")
    caption = generate_caption(user_input)
    print("üí¨ –ü–æ–¥–ø–∏—Å—å:", caption)

    print("\n‚úçÔ∏è –ù–∞–Ω–æ—Å–∏–º –ø–æ–¥–ø–∏—Å—å...")
    final_path = add_caption(image_path, caption)

    elapsed = round(time.time() - start_time, 2)
    logger.info(
        f"Model: {MODEL} | Prompt: {user_input.replace('\n', ' ').strip()} | "
        f"Visual: {visual_prompt} | Caption: {caption} | "
        f"RawFile: {os.path.basename(image_path)} | FinalFile: {os.path.basename(final_path)} | Time: {elapsed}s"
    )

    print(f"\n‚úÖ –ú–µ–º –≥–æ—Ç–æ–≤: {final_path}")
    print(f"üïí –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {elapsed} —Å–µ–∫")
    print(f"üìÅ –õ–æ–≥ –∑–∞–ø–∏—Å–∞–Ω –≤ {LOG_FILE}")


if __name__ == "__main__":
    for _ in range(10):
        main()
